question,response,time_sec,route,relevant,supported,useful
¿Es mejor tener una sola historia de usuario para la funcionalidad X o sería más conveniente descomponerla en varias?,"Hola, gracias por tu pregunta. Es una duda muy habitual y relevante en la gestión de proyectos ágiles.

Analizando la información del curso, la recomendación general es **descomponer la funcionalidad en varias historias de usuario más pequeñas y manejables**.

Las razones principales son:

1.  **Independencia entre historias**: Uno de los objetivos clave al escribir historias de usuario es que sean independientes entre sí. Según la documentación, se debe evitar la ""confianza innecesaria entre historias de usuario"" para asegurar que cada una sea independiente (fuente: `compiled.txt`). Si una historia es demasiado grande, es muy probable que genere dependencias, lo que complica la planificación y el desarrollo. Historias más pequeñas y enfocadas pueden ser desarrolladas, probadas y entregadas de forma independiente, aportando valor al cliente de manera más rápida y flexible.

2.  **Facilidad para las pruebas**: Cada historia de usuario debe ser validada mediante pruebas. De hecho, en el documento `definicionCompletado.md` se especifica que para considerar una historia completada, el producto debe superar las pruebas asociadas. Una funcionalidad grande y compleja es mucho más difícil de probar de manera exhaustiva. Al descomponerla en historias más pequeñas, cada una con un objetivo claro, se simplifica la creación de casos de prueba y tests de aceptación, asegurando que cada pequeña pieza de funcionalidad opera correctamente.

En resumen, aunque pueda parecer más trabajo al principio, descomponer una funcionalidad grande en varias historias de usuario te permitirá:
*   Gestionar mejor las dependencias.
*   Facilitar la estimación del esfuerzo.
*   Simplificar el proceso de pruebas y validación.
*   Entregar valor de forma incremental y continua.

Espero que esta explicación te sea de gran ayuda. ¡Sigue así",41.02,GRAPH,True,True,True
"En el plan de pruebas deben aparecer todos los casos de prueba unitaria de un método, pero a la hora de codificar, ¿con probar uno de ellos es suficiente?","Hola,

Gracias por tu pregunta. Es una duda muy pertinente sobre la relación entre la planificación de las pruebas y su ejecución.

Analizando la información de las asignaturas, la respuesta es clara: **no, no es suficiente probar solo uno de los casos de prueba, aunque en el plan de pruebas se listen todos.**

Aquí te explico el porqué, basándome en los conceptos del curso:

1.  **Propósito del Plan de Pruebas:** El `Plan de Pruebas` es un documento que, por definición, ""describe el alcance, el enfoque y los recursos de las actividades de prueba"" y ""especifica el conjunto de pruebas a realizar sobre un sistema para verificar su correcto funcionamiento"". Su objetivo es garantizar una cobertura completa. Si defines varios casos de prueba para un método, es porque cada `Caso de Prueba` está diseñado para verificar un escenario, una condición o un camino de ejecución diferente (por ejemplo, valores límite, entradas válidas, entradas nulas, caminos de error, etc.).

2.  **La Naturaleza del Caso de Prueba:** Cada `Caso de Prueba` es una ""especificación de las entradas, condiciones de ejecución, y resultados esperados"". Omitir la codificación y ejecución de cualquiera de ellos implica dejar una parte del comportamiento del método sin verificar, lo que crea un riesgo de que existan fallos no detectados.

3.  **Calidad y Cobertura:** El objetivo del `Testing` es ""evaluar la calidad del software, identificando errores y asegurando que cumple con los requisitos"". Para lograrlo, es fundamental la cobertura. De hecho, artefactos como el `Requirement Trace Result` se utilizan para demostrar la ""completitud de la cobertura de requisitos en los procesos de diseño y testing"". Ejecutar un solo caso de prueba de los muchos planificados daría como resultado una cobertura incompleta y, por tanto, una menor garantía de calidad.

4.  **Automatización y Builds:** Prácticas como el `Self-Testing Build` se basan en la ejecución de un conjunto completo de pruebas automatizadas. Si una sola prueba falla, todo el build se considera fallido. Este enfoque solo es efectivo si se implementan y ejecutan *todos* los casos de prueba relevantes, no solo una muestra.

En resumen, el plan de pruebas es tu guía para asegurar que el software es robusto y funciona como se espera. Debes codificar y ejecutar todos los casos de prueba que has definido en él, ya que cada uno cumple una función específica en la validación del método. Omitir casos es como construir un puente y probar solo uno de sus pilares.

Espero que esto aclare tu duda. ¡Sigue así",47.62,GRAPH,True,True,True
"Tengo que hacer el plan de pruebas de una historia de usuario y para su implementación se han modificado o creado tres clases. Mi duda es, ¿tengo que hacer pruebas unitarias para cada método de cada clase?","Hola, ¡buena pregunta! Es un punto clave a la hora de planificar las pruebas.

Analizando la información disponible, la respuesta es que **sí, el enfoque correcto es crear pruebas unitarias para los métodos de las clases que has modificado o creado**, especialmente para aquellos que contienen lógica de negocio.

Aquí te detallo el porqué:

1.  **El objetivo de la Prueba Unitaria:** Como se indica en la documentación, las pruebas unitarias se centran en ""verificar el correcto funcionamiento de componentes individuales del sistema"" y ""probar unidades individuales de código, como clases, aislándolas de dependencias externas"". La unidad más básica de comportamiento en una clase es un método, por lo que probarlos es fundamental para asegurar que la clase funciona como se espera.

2.  **Pruebas de Método:** De hecho, existe el concepto específico de **Prueba De Metodo**, definido como el tipo de prueba que se centra en ""verificar la funcionalidad y el comportamiento correcto de los métodos individuales dentro de una clase"". Esto confirma que tu plan de pruebas debe considerar cada método.

3.  **Aislamiento de Componentes:** Para probar un método de forma aislada, a menudo necesitarás simular las dependencias que este pueda tener con otras clases. Para ello se utilizan los **Objetos Mock**. Herramientas como **Mockito** son fundamentales en este proceso, ya que te permiten crear estos objetos simulados y definir su comportamiento, asegurando que estás probando únicamente la lógica de tu método y no la de sus colaboradores.

**Recomendación práctica:**

Aunque el ideal es cubrir todos los métodos, en la práctica el esfuerzo se concentra en aquellos que contienen lógica de negocio, algoritmos, condiciones o que interactúan con otras clases. Los métodos muy simples (como *getters* y *setters* básicos que no tienen ninguna lógica adicional) a veces se omiten, aunque una buena cobertura de pruebas suele incluirlos.

En resumen, para tu plan de pruebas, debes identificar los métodos clave en las tres clases (especialmente los nuevos o modificados) y diseñar casos de prueba unitarios para cada uno, utilizando Mocks cuando sea necesario para aislarlos.

Para ver ejemplos más concretos, te sugiero revisar los documentos de la asignatura **Procesos de Ingeniería de Software**, como `ps-2324-p01-mocks.pdf`, que seguramente te darán una guía práctica sobre cómo implementar estas pruebas con las herramientas adecuadas.

Espero que esto aclare tu duda. ¡Mucho ánimo con ese plan de pruebas",52.12,GRAPH,True,False,True
Describe el flujo de trabajo de una prueba automatizada con Espresso (Selección-Acción-Comprobación) y explica por qué es superior a las pruebas manuales en el contexto de la integración continua.,"¡Hola! Con gusto te explico el flujo de trabajo de Espresso y su importancia en la integración continua.

Analizando la información de los cursos, podemos desglosar tu pregunta en dos partes:

### 1. Flujo de Trabajo de Espresso: Selección - Acción - Comprobación

Espresso, como framework de pruebas de interfaz de usuario (UI) para Android, estructura las pruebas automatizadas siguiendo un flujo muy intuitivo y claro. La documentación lo describe como un proceso de tres pasos fundamentales:

1.  **Selección (Selection):** Primero, necesitas encontrar un elemento en la interfaz de usuario con el que quieras interactuar. Para esto, Espresso utiliza principalmente el método `onView()`. Este método busca en la jerarquía de vistas de la pantalla actual un componente que cumpla con ciertos criterios (por ejemplo, que tenga un ID específico, un texto determinado, etc.).

2.  **Acción (Action):** Una vez que has seleccionado el elemento, el siguiente paso es realizar una acción sobre él, simulando la interacción de un usuario. Esto se logra con el método `perform()`. Las acciones pueden ser variadas, como hacer clic, escribir texto, deslizar el dedo por la pantalla, entre otras.

3.  **Comprobación (Check):** Finalmente, después de la acción, debes verificar que el estado de la interfaz de usuario ha cambiado como esperabas. El método `check()` se encarga de esto. Permite realizar aserciones o comprobaciones sobre el estado de uno o más elementos. Por ejemplo, puedes verificar si un texto ha aparecido en pantalla, si un elemento es visible o si tiene un contenido específico.

En resumen, una prueba en Espresso localiza un componente (`onView`), ejecuta una acción sobre él (`perform`) y verifica el resultado (`check`), haciendo que las pruebas sean legibles, fiables y fáciles de mantener.

### 2. Superioridad sobre las Pruebas Manuales en Integración Continua (CI)

La integración continua es una práctica de desarrollo donde los cambios de código se integran en un repositorio centralizado de forma frecuente, y cada integración se verifica mediante una compilación y ejecución de pruebas automatizadas. Aquí es donde el enfoque de Espresso y la automatización de pruebas en general demuestran su superioridad sobre las pruebas manuales:

*   **Velocidad y Frecuencia:** En un entorno de CI, las integraciones ocurren varias veces al día. Ejecutar manualmente un conjunto completo de pruebas de regresión para la UI en cada integración sería extremadamente lento e impráctico. Las pruebas automatizadas con Espresso se ejecutan en minutos, proporcionando feedback casi inmediato a los desarrolladores.
*   **Fiabilidad y Consistencia:** Las pruebas manuales son propensas a errores humanos. Un tester puede olvidar un paso, realizarlo de forma incorrecta o interpretar un resultado de manera subjetiva. Las pruebas automatizadas, como se define en la documentación del proyecto (`pruebas.md`), son scripts que ejecutan los mismos pasos de la misma manera cada vez, garantizando resultados consistentes y fiables.
*   **Detección Temprana de Errores:** Según se indica en los artefactos del curso, las pruebas automatizadas deben ejecutarse con éxito cada vez que se integra un incremento. Si una nueva integración introduce un error (una regresión), las pruebas de Espresso fallarán inmediatamente, alertando al equipo antes de que el problema se propague a otras partes del sistema. Con pruebas manuales, estos errores podrían no descubrirse hasta mucho más tarde.
*   **Escalabilidad:** A medida que la aplicación crece, el número de casos de prueba también lo hace. Mantener la cobertura con pruebas manuales se vuelve exponencialmente más costoso y lento. La automatización de pruebas (`Test Automation`) permite ampliar la cobertura de manera sostenible, reduciendo el esfuerzo manual y asegurando que tanto las funcionalidades nuevas como las antiguas sigan funcionando correctamente.

En conclusión, el flujo estructurado de Espresso facilita la creación de **pruebas automatizadas** robustas. Estas pruebas son fundamentales en un pipeline de integración continua porque ofrecen la velocidad, fiabilidad y escalabilidad que las pruebas manuales no pueden proporcionar, asegurando así la calidad del software de manera eficiente.",48.44,GRAPH,False,False,False
"En el plan de pruebas deben aparecer todos los casos de prueba unitaria de un método, pero a la hora de codificar, ¿con probar uno de ellos es suficiente?","Hola. Es una excelente pregunta que conecta la planificación con la implementación de las pruebas.

La respuesta es que **no, no es suficiente probar solo uno de los casos de prueba definidos en el plan.**

Analizando la información de las asignaturas, podemos ver por qué:

1.  **El propósito del Plan de Pruebas:** El `Plan de Pruebas` es el documento que define el alcance, el enfoque y el conjunto de pruebas a realizar para verificar el correcto funcionamiento del sistema. Si en la fase de diseño se determinó que un método necesita varios casos de prueba, es porque cada uno de ellos está diseñado para validar un escenario, una condición o un camino de ejecución diferente (por ejemplo, un caso para datos válidos, otro para datos nulos, otro para un valor límite, etc.).

2.  **La naturaleza de un Caso de Prueba:** Un `Caso de Prueba` es una especificación con entradas, condiciones y resultados esperados concretos. Omitir la codificación de los casos de prueba definidos en el plan implica dejar partes del comportamiento del método sin verificar, lo que aumenta el riesgo de que existan errores no detectados.

3.  **El objetivo del Testing:** El objetivo final del `Testing` es evaluar la calidad del software, encontrar errores y asegurar que cumple con los requisitos. Probar un único escenario de los muchos posibles no proporciona la confianza necesaria sobre la robustez y corrección del método.

En resumen, a la hora de codificar, **debes implementar todos los casos de prueba que se han especificado en el `Plan de Pruebas`**. El plan es tu guía para asegurar una cobertura de pruebas adecuada y garantizar la calidad del software que estás desarrollando.",50.69,GRAPH,False,False,False
"Tengo que hacer el plan de pruebas de una historia de usuario y para su implementación se han modificado o creado tres clases. Mi duda es, ¿tengo que hacer pruebas unitarias para cada método de cada clase? ¿Y cómo pongo los valores de entrada? Si no tiene entrada como tal, solo es el hecho de hacer click en un botón y se abre una pantalla.","¡Hola! Entiendo perfectamente tu duda, es una pregunta muy común al momento de planificar las pruebas de una historia de usuario. Vamos a desglosar la respuesta basándonos en los conceptos de la asignatura.

### 1. ¿Tengo que hacer pruebas unitarias para cada método de cada clase?

No necesariamente para *cada método*, pero sí para cada **unidad de comportamiento o lógica de negocio**.

Analizando la documentación del curso, las **pruebas unitarias** se centran en verificar el correcto funcionamiento de **componentes individuales** del software de forma **aislada**. Esto significa que el objetivo es probar la lógica que has implementado.

*   **Métodos con lógica:** Si un método contiene lógica de negocio, condicionales, bucles o realiza algún cálculo importante, definitivamente debes crear una prueba unitaria para él. El objetivo es cubrir los diferentes caminos que puede tomar la ejecución de ese método.
*   **Métodos simples:** Métodos muy sencillos como *getters* o *setters* que simplemente asignan o devuelven un valor, generalmente no se prueban de forma unitaria, ya que no contienen lógica compleja. Probarlos no aporta mucho valor.

En resumen, enfócate en probar la funcionalidad y la lógica de tus clases, no en tener una prueba por cada método existente de manera obligatoria.

### 2. ¿Cómo pongo los valores de entrada?

Aquí es donde entran en juego los **objetos Mock y Stub**. La información de la asignatura indica que las pruebas unitarias los utilizan para simular dependencias y poder probar las clases de forma aislada.

*   **Entradas directas:** Si tu método recibe parámetros simples (ej: `calcularTotal(int cantidad, double precio)`), en tu prueba simplemente llamas al método pasándole diferentes valores y verificas que el resultado sea el esperado.
    ```java
    // En tu clase de prueba
    MiClase miObjeto = new MiClase();
    double resultado = miObjeto.calcularTotal(5, 10.0);
    assertEquals(50.0, resultado);
    ```

*   **Entradas a través de dependencias:** Si tu método depende de otro objeto para obtener un valor (ej: `obtenerPrecioDeBaseDeDatos()`), no quieres que tu prueba unitaria acceda a la base de datos real. Para eso, simulas esa dependencia.
    *   Creas un **Objeto Mock** de la clase de la que dependes (por ejemplo, un `Repositorio`).
    *   Configuras el Mock para que, cuando se llame a su método (`obtenerPrecio()`), devuelva un valor que tú controlas (ej: `10.0`).
    *   De esta forma, estás ""inyectando"" el valor de entrada a través de la dependencia simulada, permitiendo probar tu clase de forma aislada. Frameworks como **Mockito**, que se mencionan en la documentación, son ideales para esto.

### 3. ¿Y si la entrada es un clic en un botón?

Este es un punto clave. La acción de ""hacer clic en un botón y que se abra una pantalla"" involucra varios componentes (la vista, el controlador/viewModel, la lógica de navegación, etc.). Una única prueba unitaria no puede verificar todo ese flujo. Debes separar las responsabilidades:

1.  **Prueba Unitaria de la Lógica:** El clic en el botón seguramente ejecuta un método en tu lógica (por ejemplo, en un `ViewModel` o `Presenter`). **Ese método es el que debes probar unitariamente**. No simulas el clic, sino que llamas directamente al método en tu test.
    *   **Ejemplo:** Imagina que el clic llama a `viewModel.onBotonSiguientePulsado()`. Tu prueba unitaria llamará directamente a ese método.
    *   **Verificación:** Dentro de la prueba, verificarás el resultado de esa llamada. ¿Cambió algún estado en el `ViewModel`? ¿Llamó a otro objeto (que tendrías como un Mock) para preparar los datos de la siguiente pantalla? Esto es lo que se conoce como **verificación de comportamiento**, un concepto que, según la documentación, está asociado al uso de Mocks y frameworks como Mockito.

2.  **Prueba de Interfaz de Usuario (UI Test):** La verificación de que ""al hacer clic, realmente se abre la nueva pantalla"" es una **prueba de instrumentación o de UI**, no una prueba unitaria. Para esto se usan herramientas como Espresso (mencionado en el documento `ps-2324-semExpresso.pdf`). Este tipo de prueba sí simula la interacción del usuario con la pantalla y verifica los resultados visuales, como una transición de pantalla.

En conclusión, para tu plan de pruebas:
*   **Identifica la lógica de negocio** en tus tres clases y crea **pruebas unitarias** para esos métodos.
*   Usa **objetos Mock** con **Mockito** para aislar las clases de sus dependencias y controlar las ""entradas"" que reciben de otros componentes.
*   Para la interacción del botón, crea una **prueba unitaria** para el método que se ejecuta tras el clic y, si es necesario, una **prueba de UI** separada para verificar la navegación.

Espero que esto aclare tus dudas. ¡Mucho ánimo con ese plan de pruebas",61.75,GRAPH,False,False,False
¿En qué actividades tengo que ser yo el que le pida al profesor que me evalúe?,"Analizando la información disponible en los documentos del curso, no se especifica ninguna actividad en la que tú, como estudiante, debas solicitar explícitamente la evaluación al profesor.

La documentación, como el fichero `ejercicioSeguridadAsignacion.docx`, se centra principalmente en la gestión y seguridad de las tareas desde la perspectiva del sistema y del profesor. Se detalla cómo se realiza la `Asignación de Tareas` y los riesgos asociados, como la `Eliminación No Deseada` o la `Modificación No Deseada` de las mismas, pero no se describe el proceso de evaluación una vez que el alumno ha completado el trabajo.

Basándome en la práctica habitual en asignaturas de Ingeniería del Software, el procedimiento estándar es que entregues tu trabajo antes de una fecha límite establecida, y la evaluación se inicia automáticamente por parte del profesor.

Sin embargo, podrías necesitar una acción más proactiva en situaciones como:

*   **Defensas de proyectos o presentaciones:** Donde es posible que necesites coordinar una fecha y hora con el profesor para ser evaluado.
*   **Entregas con revisión de código (Code Review):** En plataformas de desarrollo colaborativo, es común que al finalizar una funcionalidad crees una ""solicitud de integración"" (Pull/Merge Request). Este acto notifica formalmente al profesor que tu trabajo está listo para ser revisado y evaluado.
*   **Revisiones de avance en proyectos largos:** Es posible que tengas que solicitar reuniones periódicas para mostrar tu progreso y recibir feedback, lo cual forma parte de una evaluación continua.

Te recomiendo revisar la guía docente de la asignatura para confirmar el procedimiento exacto o consultarlo directamente con tu profesor, ya que es la fuente más fiable para este tipo de detalles operativos.",52.64,GRAPH,True,False,True
¿En qué actividades evaluables tengo 3 intentos?,"Analizando la información disponible sobre las asignaturas, no se ha encontrado ninguna referencia específica que indique cuáles de las actividades evaluables disponen de 3 intentos.

La documentación define el concepto de **Actividad** como un conjunto de tareas que pueden ser evaluadas e influir en la calificación, pero no detalla la normativa de evaluación para cada una de ellas, como el número de intentos permitidos.

Para obtener esa información, te recomiendo consultar la guía docente oficial de la asignatura o preguntar directamente al profesor responsable, ya que es el lugar donde se suelen especificar las políticas de evaluación y el número de oportunidades para cada entrega o examen.",34.1,GRAPH,True,True,True
¿Cuantas veces por sprint me voy a reunir con el Product Owner?,"Basándome en el contexto proporcionado, te reunirás con el Product Owner al menos dos veces por sprint en reuniones formales:

1.  **Sprint Planning Meeting I**: Se realiza **al comienzo de cada sprint**. En esta reunión, el equipo Scrum colabora con el Product Owner para seleccionar los elementos del Product Backlog que se desarrollarán.
2.  **Product Review**: Tiene lugar **al inicio del segundo viernes de cada sprint**. Durante esta sesión, el equipo muestra el trabajo realizado al Product Owner para verificar que el producto cumple con lo esperado.",31.44,VECTOR,True,True,True
¿En qué asignaturas es evaluable que haya hecho el Informe de Calidad?,"Hola,

Analizando la documentación de las asignaturas, el **Informe de Calidad** es un artefacto evaluable específicamente en la asignatura de **Proyecto Integrado**.

Este informe es un documento que se genera periódicamente durante los **Sprints** para evaluar el estado de la calidad del software. Según se indica en los documentos de evaluación de la asignatura (`evaluacion.md` y `evaluacionCalidad.md` en la carpeta de `proyecto_Integrado`), este informe representa un 10% de la calificación final.

Para su elaboración, es necesario utilizar los análisis generados por herramientas como **SonarCloud**, que sirven como base para identificar problemas y planificar las acciones de mejora correspondientes.",43.72,GRAPH,True,True,True
"Si no creo el apk, ¿cuanto me afectará a la nota?","Analizando la documentación proporcionada, como los ficheros del examen `ir-Ordinaria-2025`, no he encontrado información específica sobre los criterios de evaluación o la penalización exacta por no entregar el archivo APK.

Sin embargo, basándome en la práctica habitual en las asignaturas de Ingeniería del Software, puedo darte una orientación general:

El archivo APK es el resultado tangible y ejecutable de tu proyecto; es la **Aplicacion** final que un usuario, en este caso el profesor, puede instalar y probar. Su entrega es fundamental por varias razones:

1.  **Validación Funcional:** Sin el APK, es imposible realizar las **Pruebas de Aceptacion** para verificar si la aplicación cumple con los requisitos y si los **Casos de Uso** (como, por ejemplo, **Realizar Apuesta**) se han implementado correctamente.
2.  **Evidencia de Trabajo:** Es la principal evidencia de que el desarrollo se ha completado y de que los **Objetivos** del proyecto se han materializado en un producto funcional.

Por lo tanto, no entregar el APK probablemente tenga un impacto muy significativo y negativo en tu nota. Se considera un entregable crítico y su ausencia podría implicar que la parte práctica de la asignatura no se pueda evaluar, llevando a un suspenso en esa sección.

Mi recomendación es que priorices la generación y entrega del APK. Si estás encontrando dificultades técnicas para crearlo, es crucial que consultes con tu profesor lo antes posible.",42.5,GRAPH,True,False,True
¿Qué debo hacer si Github Actions me dice que las pruebas no han pasado?,"Hola. Cuando GitHub Actions te informa que las pruebas no han pasado, está señalando un **`Failure`** (fallo) en el proceso de integración.

Según la documentación del curso, un `Failure` se define como una instancia en la que el software no se comporta como se esperaba durante las pruebas. Específicamente para tu caso, la política de configuración del **Proyecto Integrado** establece que un `Failure` es ""un estado que indica la ejecución no exitosa de GitHub Actions, marcando el correspondiente commit"" (*politicaConfiguracion.md*).

Esto significa que las pruebas automatizadas (como las **pruebas unitarias** o de **integración**) han detectado un **fallo funcional** o un problema de integración en los cambios que has subido.

Para solucionarlo, tu objetivo es la **`Failure Elimination`** (eliminación del fallo). Te recomiendo seguir estos pasos:

1.  **Analiza el informe de GitHub Actions:** Revisa los registros (logs) de la ejecución fallida. Allí podrás ver qué pruebas concretas no han pasado y los mensajes de error detallados.
2.  **Identifica la causa del fallo:** El error te dará pistas sobre si es un problema en una unidad de código específica o un problema de interacción entre varios componentes.
3.  **Depura y corrige el código:** Replica el error en tu entorno de desarrollo local para entenderlo mejor. Una vez localizado, aplica la corrección necesaria en el código.
4.  **Vuelve a ejecutar las pruebas localmente:** Antes de subir los cambios de nuevo, asegúrate de que las pruebas pasan en tu máquina.
5.  **Envía la corrección:** Realiza un nuevo commit con la solución y súbelo al repositorio. Esto volverá a ejecutar las GitHub Actions.

El `Failure` indica la presencia de problemas que deben resolverse antes de que se puedan integrar más cambios en el proyecto. Corregirlo asegura la calidad y el correcto funcionamiento del software.",50.38,GRAPH,False,False,False
Hazme una lista de todos los elementos que se evalúan en el proyecto integrado,"Basándome en la información del contexto, no se proporciona una lista detallada y exhaustiva de cada uno de los ""elementos evaluables"". El texto menciona que existe una tabla para la asignatura de Calidad y Auditoría, pero no se incluye en el fragmento.

Sin embargo, sí se mencionan las **áreas generales** que se evalúan dentro del proyecto integrado. Estas son:

*   **Gestión de la configuración:** Incluyendo el manejo de ramas, integración continua, etc.
*   **Pruebas:** Abarcando el plan de pruebas, pruebas unitarias, de integración, etc.
*   **Calidad de producto:** Evaluando el proceso seguido, los informes generados, etc.
*   **Documentación:** Comprendiendo diagramas, manuales, etc.

Además, una vez finalizados los sprints, se evalúan dos actividades específicas relacionadas con la calidad del proceso:

*   **Creación de una lista de comprobación:** Cada grupo debe crear una lista para auditar la metodología del proyecto.
*   **Auditorías cruzadas:** Cada grupo audita el proceso de otro grupo utilizando la lista de comprobación creada.",31.85,VECTOR,True,True,True
¿Cuál es el elemento evaluable más importante en la asignatura Métodos de Desarrollo?,"Analizando la información disponible de las asignaturas, no se especifica un único ""elemento evaluable más importante"" con una ponderación superior a los demás para la asignatura de Métodos de Desarrollo.

Sin embargo, la documentación deja claro que la evaluación de esta asignatura está directamente centrada en el **Proyecto Integrado**. Según se indica en los documentos de evaluación del proyecto (como `evaluacion.md`), el proceso consiste en determinar el valor y la calidad del trabajo realizado en dicho proyecto.

Concretamente, lo que se evalúa son los **""Elementos Evaluables del Método de Desarrollo""**, es decir, cómo aplicas los aspectos específicos de la metodología de desarrollo elegida para determinar su eficacia y calidad en un contexto práctico.

En resumen, aunque no se destaca un único artefacto o entrega como el más importante, la **aplicación práctica y correcta de los métodos de desarrollo a lo largo del Proyecto Integrado** es el eje central sobre el que gira toda la evaluación de la asignatura.",44.54,GRAPH,True,True,True
¿Qué herramientas voy a necesitar utilizar en el Proyecto Integrado? Dime donde se mencionan.,"Según el contexto proporcionado, la lista de herramientas necesarias para el Proyecto Integrado se menciona en la sección titulada **""# Herramientas""**.

Concretamente, el texto indica:

> ""Esta página contiene una lista de las herramientas que se utilizarán para el desarrollo del proyecto integrado; así como las instrucciones necesarias para su instalación y configuración.""

Por lo tanto, aunque el contexto no enumera las herramientas específicas, sí te indica que puedes encontrar esa lista en la página o documento del que se ha extraído este fragmento, bajo ese mismo encabezado.",26.11,VECTOR,True,True,True
