question,response,time_sec,route,relevant,supported,useful
¿Es mejor tener una sola historia de usuario para la funcionalidad X o sería más conveniente descomponerla en varias?,"Analizando la información disponible, la recomendación general es descomponer una funcionalidad compleja en varias historias de usuario más pequeñas y manejables. La razón principal se centra en el concepto de **independencia**.

Según los principios de desarrollo que se manejan, se debe evitar la dependencia innecesaria entre historias de usuario para asegurar que cada una sea independiente. Si mantienes la funcionalidad X como una única historia de gran tamaño, es muy probable que genere dependencias complejas y dificulte su gestión, desarrollo y prueba.

Descomponerla en historias más pequeñas te aporta varias ventajas:

1.  **Facilita las pruebas**: Cada historia de usuario debe poder ser validada de forma independiente. Como se indica en el documento `definicionCompletado.md`, para que una historia se considere completada, debe superar las pruebas definidas para ella. Es mucho más sencillo definir y ejecutar pruebas para una funcionalidad pequeña y específica que para una grande y compleja.

2.  **Promueve la independencia**: Al dividir la funcionalidad, puedes trabajar en piezas que entregan valor por sí mismas sin depender de que otras partes estén terminadas. Esto reduce cuellos de botella y permite un flujo de trabajo más ágil.

3.  **Mejora la estimación y planificación**: Es más fácil estimar el esfuerzo requerido para una historia pequeña y bien definida. Esto permite al equipo planificar los sprints de manera más precisa y entregar valor de forma incremental y constante.

En resumen, aunque pueda parecer más trabajo al principio, descomponer la funcionalidad X en varias historias de usuario te ayudará a crear un producto de mayor calidad, facilitará las pruebas y permitirá una gestión más eficiente del proyecto.",26.32,GRAPH,False,False,False
"En el plan de pruebas deben aparecer todos los casos de prueba unitaria de un método, pero a la hora de codificar, ¿con probar uno de ellos es suficiente?","Hola,

Gracias por tu pregunta. Es una duda muy pertinente sobre la relación entre la planificación de las pruebas y su ejecución.

Analizando la información de las asignaturas, la respuesta es clara: **no, no es suficiente probar solo uno de los casos de prueba, aunque en el plan de pruebas se listen todos.**

Aquí te explico el porqué, basándome en los conceptos del curso:

1.  **Propósito del Plan de Pruebas:** El `Plan de Pruebas` es un documento que, por definición, ""describe el alcance, el enfoque y los recursos de las actividades de prueba"" y ""especifica el conjunto de pruebas a realizar sobre un sistema para verificar su correcto funcionamiento"". Su objetivo es garantizar una cobertura completa. Si defines varios casos de prueba para un método, es porque cada `Caso de Prueba` está diseñado para verificar un escenario, una condición o un camino de ejecución diferente (por ejemplo, valores límite, entradas válidas, entradas nulas, caminos de error, etc.).

2.  **La Naturaleza del Caso de Prueba:** Cada `Caso de Prueba` es una ""especificación de las entradas, condiciones de ejecución, y resultados esperados"". Omitir la codificación y ejecución de cualquiera de ellos implica dejar una parte del comportamiento del método sin verificar, lo que crea un riesgo de que existan fallos no detectados.

3.  **Calidad y Cobertura:** El objetivo del `Testing` es ""evaluar la calidad del software, identificando errores y asegurando que cumple con los requisitos"". Para lograrlo, es fundamental la cobertura. De hecho, artefactos como el `Requirement Trace Result` se utilizan para demostrar la ""completitud de la cobertura de requisitos en los procesos de diseño y testing"". Ejecutar un solo caso de prueba de los muchos planificados daría como resultado una cobertura incompleta y, por tanto, una menor garantía de calidad.

4.  **Automatización y Builds:** Prácticas como el `Self-Testing Build` se basan en la ejecución de un conjunto completo de pruebas automatizadas. Si una sola prueba falla, todo el build se considera fallido. Este enfoque solo es efectivo si se implementan y ejecutan *todos* los casos de prueba relevantes, no solo una muestra.

En resumen, el plan de pruebas es tu guía para asegurar que el software es robusto y funciona como se espera. Debes codificar y ejecutar todos los casos de prueba que has definido en él, ya que cada uno cumple una función específica en la validación del método. Omitir casos es como construir un puente y probar solo uno de sus pilares.

Espero que esto aclare tu duda. ¡Sigue así",30.62,GRAPH,False,False,False
"Tengo que hacer el plan de pruebas de una historia de usuario y para su implementación se han modificado o creado tres clases. Mi duda es, ¿tengo que hacer pruebas unitarias para cada método de cada clase?","Hola, claro que te ayudo con tu duda.

Analizando la información de las asignaturas, la respuesta es que **sí, el enfoque principal de las pruebas unitarias es verificar el comportamiento de los métodos individuales**.

Aquí te detallo el porqué:

1.  **Objetivo de la Prueba Unitaria:** Las pruebas unitarias, por definición, se centran en verificar el correcto funcionamiento de las unidades más pequeñas de código, como son las funciones o los métodos de una clase. Su objetivo es asegurar que cada pieza del software funciona correctamente de forma aislada antes de integrarla con otras.

2.  **Pruebas de Método:** De hecho, la documentación contempla el concepto de **Prueba de Método**, que se define específicamente como el tipo de prueba enfocado en ""verificar el comportamiento y la correcta ejecución de los métodos de una clase"". Esto confirma que tu plan de pruebas debe considerar los métodos como el objetivo principal.

3.  **Enfoque práctico:** Para tu plan de pruebas, deberías centrarte en los métodos que has creado o modificado en esas tres clases y que contienen la lógica de negocio de la historia de usuario. Es crucial probar que cada uno de ellos se comporta como se espera.

    *   **¿Significa esto probar absolutamente todos los métodos?** En la práctica, el esfuerzo se concentra en aquellos métodos con lógica relevante (condicionales, bucles, cálculos, llamadas a otros componentes, etc.). Métodos muy simples, como *getters* o *setters* básicos que no tienen ninguna lógica adicional, a menudo se consideran de bajo riesgo y no siempre se les crea una prueba unitaria dedicada, aunque esto puede variar según la política de calidad del proyecto.

4.  **Aislamiento de componentes:** Para poder probar un método de una clase sin depender de otras, la documentación de la asignatura *Procesos de Ingeniería de Software* (por ejemplo, en el documento `ps-2324-p01-mocks.pdf`) destaca el uso de **Objetos Mock**. Estos objetos simulan las dependencias que pueda tener tu clase, permitiéndote verificar el comportamiento de tus métodos de manera controlada y aislada. Para ello, se utilizan *frameworks* como **Mockito** en conjunto con **JUnit**.

En resumen, para tu plan de pruebas, debes identificar los métodos clave en las tres clases afectadas y diseñar casos de prueba unitarios para cada uno, asegurando que su comportamiento es el correcto.

Espero que esto aclare tu duda. ¡Mucho ánimo con ese plan de pruebas",32.36,GRAPH,False,False,False
Describe el flujo de trabajo de una prueba automatizada con Espresso (Selección-Acción-Comprobación) y explica por qué es superior a las pruebas manuales en el contexto de la integración continua.,"¡Hola! Con gusto te ayudo a resolver tu duda sobre Espresso y la integración continua.

Analizando la información de las asignaturas, podemos desglosar tu pregunta en dos partes: el flujo de trabajo de Espresso y su ventaja en la integración continua.

### Flujo de Trabajo de una Prueba con Espresso

Efectivamente, el flujo de una prueba de interfaz de usuario (UI) con Espresso se basa en un ciclo de tres pasos claros y concisos, tal como se describe en la documentación de la asignatura *Procesos de Ingeniería de Software*. Este flujo es:

1.  **Selección (Encontrar un elemento):** El primer paso es localizar un componente específico en la interfaz de la aplicación con el que se quiere interactuar. Para esto, Espresso utiliza métodos como `onView()` para vistas generales o `onData()` para elementos dentro de listas o adaptadores. Estos métodos reciben `Matchers` que actúan como criterios de búsqueda (por ejemplo, buscar un botón por su ID o por el texto que muestra).

2.  **Acción (Realizar una acción):** Una vez que el elemento ha sido seleccionado, el siguiente paso es simular una interacción del usuario sobre él. Esto se logra con el método `perform()`, que puede ejecutar acciones como hacer clic (`click()`), escribir texto (`typeText()`), o deslizar (`swipeLeft()`).

3.  **Comprobación (Verificar el resultado):** Tras la acción, es fundamental verificar que la interfaz de la aplicación ha reaccionado de la manera esperada. El método `check()` se encarga de esta fase, utilizando aserciones (`ViewAssertions`) para comprobar el estado de uno o más elementos. Por ejemplo, se puede verificar si un texto ha aparecido en pantalla (`matches(isDisplayed())`) o si su contenido es el correcto (`matches(withText(""...""))`).

Este ciclo ""Selección-Acción-Comprobación"" hace que las pruebas sean muy legibles y fáciles de mantener.

### Superioridad de las Pruebas Automatizadas en Integración Continua (CI)

En el contexto de la integración continua, donde el objetivo es integrar cambios de código de forma frecuente y automática, las pruebas automatizadas con Espresso son superiores a las pruebas manuales por varias razones clave, fundamentadas en los principios de la asignatura:

*   **Velocidad y Eficiencia:** Las pruebas automatizadas se ejecutan mucho más rápido que cualquier prueba manual. En un entorno de CI, cada vez que un desarrollador sube código nuevo, se dispara un proceso de compilación y prueba. La velocidad de Espresso permite obtener feedback casi inmediato, indicando si el nuevo cambio ha roto alguna funcionalidad existente. Una prueba manual sería un cuello de botella que ralentizaría todo el ciclo de desarrollo.

*   **Consistencia y Fiabilidad:** Como se menciona en la documentación del *Proyecto Integrado*, un **Automated Test** debe ejecutarse con éxito para que un incremento de software pueda ser integrado. Las pruebas con Espresso son deterministas: siempre ejecutan los mismos pasos de la misma manera, eliminando el riesgo de error humano o la variabilidad que introduce un tester manual. Esto garantiza que si una prueba falla, es debido a un problema real en el código.

*   **Automatización del Proceso:** El concepto de **Test Automation** se centra en reducir el esfuerzo manual. En un pipeline de CI, las pruebas se ejecutan sin intervención humana. Esto no sería posible con pruebas manuales, que requerirían que una persona estuviera constantemente disponible para probar cada pequeño cambio, lo cual es inviable.

*   **Regresión Continua:** Las pruebas automatizadas con Espresso crean una red de seguridad. A medida que la aplicación crece, el conjunto de pruebas también lo hace, verificando no solo las nuevas funcionalidades sino también asegurando que las antiguas no se hayan roto (pruebas de regresión). En un entorno de CI, esta red de seguridad se verifica con cada cambio, algo que sería extremadamente tedioso y propenso a errores si se hiciera manualmente.

En resumen, mientras que las pruebas manuales son útiles para pruebas exploratorias, la velocidad, fiabilidad y capacidad de automatización de Espresso lo convierten en una herramienta fundamental para garantizar la calidad del software en un proceso de integración continua, tal como se estudia en las asignaturas de *Procesos de Ingeniería de Software* y se aplica en el *Proyecto Integrado*.

Espero que esta explicación te sea de gran ayuda. ¡Si tienes más dudas, no dudes en preguntar",36.97,GRAPH,False,False,False
"En el plan de pruebas deben aparecer todos los casos de prueba unitaria de un método, pero a la hora de codificar, ¿con probar uno de ellos es suficiente?","¡Hola! Soy TutorIS, tu tutor de Ingeniería del Software. Vamos a resolver tu duda.

Basándome en la información de las asignaturas, la respuesta corta es: **no, no es suficiente probar solo uno de los casos de prueba.** Debes codificar todos los casos de prueba que has definido en tu plan de pruebas.

Aquí te explico por qué:

1.  **El Plan de Pruebas guía la implementación:** El `Plan de Pruebas` no es solo un documento teórico. Según la documentación, es el artefacto que ""especifica el conjunto de pruebas a realizar sobre un sistema para verificar su correcto funcionamiento"" y, en el contexto del proyecto, ""indica las pruebas implementadas en el código de la aplicación"". Esto significa que debe existir una correspondencia directa entre lo que planificas y lo que finalmente codificas. El plan es tu hoja de ruta para la implementación de las pruebas.

2.  **El objetivo es la calidad y la cobertura:** El propósito del `Testing` es ""evaluar la calidad del software, identificando errores y asegurando que cumple con los requisitos"". Cada `Caso de Prueba` se diseña para verificar una condición específica, una ruta de ejecución o un valor límite del método. Si solo implementas un caso, dejas la mayor parte del comportamiento del método sin verificar, lo que podría ocultar errores importantes.

3.  **Completitud de los requisitos:** Un concepto relevante es el `Requirement Trace Result`, que muestra la ""completitud de la cobertura de requisitos en los procesos de diseño y pruebas"". Para asegurar que un requisito está completamente cubierto, necesitas implementar todos los casos de prueba que lo validan. Omitir casos de prueba equivale a una cobertura incompleta.

En resumen, el plan de pruebas detalla *todos* los escenarios que son necesarios para garantizar que un método funciona correctamente. Implementar solo uno de ellos invalida el propósito de haber diseñado un conjunto completo de pruebas y deja la calidad del software en entredicho. Para una correcta validación, es fundamental que todos los casos de prueba definidos en el plan sean implementados y ejecutados.",32.15,GRAPH,False,False,False
"Tengo que hacer el plan de pruebas de una historia de usuario y para su implementación se han modificado o creado tres clases. Mi duda es, ¿tengo que hacer pruebas unitarias para cada método de cada clase? ¿Y cómo pongo los valores de entrada? Si no tiene entrada como tal, solo es el hecho de hacer click en un botón y se abre una pantalla.","¡Hola! Entiendo perfectamente tu duda, es una pregunta muy común al momento de planificar las pruebas de una historia de usuario. Vamos a desglosar la respuesta basándonos en los conceptos de la asignatura.

### 1. ¿Tengo que hacer pruebas unitarias para cada método de cada clase?

No necesariamente para *cada método*, pero sí para cada **unidad de comportamiento o lógica de negocio**.

Analizando la documentación del curso, las **pruebas unitarias** se centran en verificar el correcto funcionamiento de **componentes individuales** del software de forma **aislada**. Esto significa que el objetivo es probar la lógica que has implementado.

*   **Métodos con lógica:** Si un método contiene lógica de negocio, condicionales, bucles o realiza algún cálculo importante, definitivamente debes crear una prueba unitaria para él. El objetivo es cubrir los diferentes caminos que puede tomar la ejecución de ese método.
*   **Métodos simples:** Métodos muy sencillos como *getters* o *setters* que simplemente asignan o devuelven un valor, generalmente no se prueban de forma unitaria, ya que no contienen lógica compleja. Probarlos no aporta mucho valor.

En resumen, enfócate en probar la funcionalidad y la lógica de tus clases, no en tener una prueba por cada método existente de manera obligatoria.

### 2. ¿Cómo pongo los valores de entrada?

Aquí es donde entran en juego los **objetos Mock y Stub**. La información de la asignatura indica que las pruebas unitarias los utilizan para simular dependencias y poder probar las clases de forma aislada.

*   **Entradas directas:** Si tu método recibe parámetros simples (ej: `calcularTotal(int cantidad, double precio)`), en tu prueba simplemente llamas al método pasándole diferentes valores y verificas que el resultado sea el esperado.
    ```java
    // En tu clase de prueba
    MiClase miObjeto = new MiClase();
    double resultado = miObjeto.calcularTotal(5, 10.0);
    assertEquals(50.0, resultado);
    ```

*   **Entradas a través de dependencias:** Si tu método depende de otro objeto para obtener un valor (ej: `obtenerPrecioDeBaseDeDatos()`), no quieres que tu prueba unitaria acceda a la base de datos real. Para eso, simulas esa dependencia.
    *   Creas un **Objeto Mock** de la clase de la que dependes (por ejemplo, un `Repositorio`).
    *   Configuras el Mock para que, cuando se llame a su método (`obtenerPrecio()`), devuelva un valor que tú controlas (ej: `10.0`).
    *   De esta forma, estás ""inyectando"" el valor de entrada a través de la dependencia simulada, permitiendo probar tu clase de forma aislada. Frameworks como **Mockito**, que se mencionan en la documentación, son ideales para esto.

### 3. ¿Y si la entrada es un clic en un botón?

Este es un punto clave. La acción de ""hacer clic en un botón y que se abra una pantalla"" involucra varios componentes (la vista, el controlador/viewModel, la lógica de navegación, etc.). Una única prueba unitaria no puede verificar todo ese flujo. Debes separar las responsabilidades:

1.  **Prueba Unitaria de la Lógica:** El clic en el botón seguramente ejecuta un método en tu lógica (por ejemplo, en un `ViewModel` o `Presenter`). **Ese método es el que debes probar unitariamente**. No simulas el clic, sino que llamas directamente al método en tu test.
    *   **Ejemplo:** Imagina que el clic llama a `viewModel.onBotonSiguientePulsado()`. Tu prueba unitaria llamará directamente a ese método.
    *   **Verificación:** Dentro de la prueba, verificarás el resultado de esa llamada. ¿Cambió algún estado en el `ViewModel`? ¿Llamó a otro objeto (que tendrías como un Mock) para preparar los datos de la siguiente pantalla? Esto es lo que se conoce como **verificación de comportamiento**, un concepto que, según la documentación, está asociado al uso de Mocks y frameworks como Mockito.

2.  **Prueba de Interfaz de Usuario (UI Test):** La verificación de que ""al hacer clic, realmente se abre la nueva pantalla"" es una **prueba de instrumentación o de UI**, no una prueba unitaria. Para esto se usan herramientas como Espresso (mencionado en el documento `ps-2324-semExpresso.pdf`). Este tipo de prueba sí simula la interacción del usuario con la pantalla y verifica los resultados visuales, como una transición de pantalla.

En conclusión, para tu plan de pruebas:
*   **Identifica la lógica de negocio** en tus tres clases y crea **pruebas unitarias** para esos métodos.
*   Usa **objetos Mock** con **Mockito** para aislar las clases de sus dependencias y controlar las ""entradas"" que reciben de otros componentes.
*   Para la interacción del botón, crea una **prueba unitaria** para el método que se ejecuta tras el clic y, si es necesario, una **prueba de UI** separada para verificar la navegación.

Espero que esto aclare tus dudas. ¡Mucho ánimo con ese plan de pruebas",43.52,GRAPH,False,False,False
¿En qué actividades tengo que ser yo el que le pida al profesor que me evalúe?,"Lo siento, no estoy seguro de cómo clasificar tu pregunta. ¿Podrías reformularla?",19.14,UNKNOWN,False,False,False
¿En qué actividades evaluables tengo 3 intentos?,"Hola. Analizando la información disponible sobre las asignaturas, no he encontrado detalles específicos que indiquen cuáles de las actividades evaluables tienen exactamente tres intentos.

La documentación define una **Actividad** como una tarea o conjunto de tareas que pueden estar sujetas a evaluación, como se menciona en las definiciones: ""Tareas realizadas en el aula cuyo contenido se evalúa en las pruebas de la asignatura"" o ""Tarea o labor desarrollada por un equipo, sujeta a evaluación"". Sin embargo, no se especifica el número de intentos permitidos para cada una.

Generalmente, la política de intentos varía según el tipo de actividad:

*   **Cuestionarios o pruebas en línea:** Suelen ser el tipo de actividad donde es más común encontrar múltiples intentos.
*   **Entregas de proyecto o prácticas:** Habitualmente tienen un número más restringido de entregas formales.

Para obtener una respuesta precisa, te recomiendo que consultes la guía docente de la asignatura o preguntes directamente al profesor, ya que allí se detallará la normativa de evaluación específica para cada entregable.",27.04,GRAPH,False,False,False
¿Cuantas veces por sprint me voy a reunir con el Product Owner?,"Basándome en el contexto proporcionado, te reunirás con el Product Owner al menos dos veces por sprint en reuniones formales:

1.  **Sprint Planning Meeting I**: Se realiza **al comienzo de cada sprint**. En esta reunión, el equipo Scrum colabora con el Product Owner para seleccionar los elementos del Product Backlog que se desarrollarán.

2.  **Product Review**: Tiene lugar **al inicio del segundo viernes de cada sprint**. Durante esta sesión, el equipo muestra el trabajo realizado al Product Owner para verificar que se adecúa a lo esperado.",16.28,VECTOR,False,False,False
¿En qué asignaturas es evaluable que haya hecho el Informe de Calidad?,"Hola,

Analizando la información de la asignatura, el **Informe de Calidad** es un elemento evaluable específicamente en la asignatura de **Proyecto Integrado**.

La documentación establece que este informe se genera al final de cada sprint para evaluar el estado de la calidad del software. De hecho, en el documento `evaluacion.md` se menciona que representa un 10% de la evaluación de la asignatura.

Además, el concepto de `Evaluacion De Calidad` se define como un elemento que, precisamente, incluye los informes como parte de la evaluación del curso, lo que confirma su peso en la calificación final.

Espero que esto resuelva tu duda. ¡Mucho ánimo",23.56,GRAPH,False,False,False
"Si no creo el apk, ¿cuanto me afectará a la nota?","Hola,

Analizando la documentación disponible, como los archivos del examen `ir-Ordinaria-2025.docx`, no se detalla la ponderación exacta en la nota por no entregar el fichero APK. La información se centra en los conceptos y artefactos de la ingeniería de requisitos, como el caso de uso ""Realizar Apuesta"" y sus componentes.

Sin embargo, basándome en mi conocimiento general de la Ingeniería del Software y la estructura de los proyectos en estas asignaturas, puedo darte una orientación clara:

El fichero APK es el artefacto final que demuestra que la **Aplicación** ha sido construida y es funcional. Es la evidencia tangible de que has superado la fase de implementación. Sin él, es imposible llevar a cabo las **Pruebas de Aceptación**, que son cruciales para verificar que los **Casos de Uso** definidos (como el de ""Realizar Apuesta"" para el **Jugador de Apuestas**) se han implementado correctamente y cumplen con los objetivos del sistema.

En resumen, no entregar el APK equivale a no entregar el producto final. Por lo tanto, es muy probable que el impacto en tu nota sea **muy significativo**, afectando gravemente a toda la parte práctica de la evaluación.

Te recomiendo que priorices la generación del APK, ya que es una parte fundamental de la entrega del proyecto. Si tienes dificultades técnicas para crearlo, sería buena idea que consultaras con el profesor.",29.2,GRAPH,False,False,False
¿Qué debo hacer si Github Actions me dice que las pruebas no han pasado?,"Hola. Si GitHub Actions indica que las pruebas no han pasado, significa que se ha producido un **`Failure`** (fallo) en la ejecución de las tareas automáticas configuradas para tu proyecto.

Analizando la información del curso, esto es lo que debes saber y hacer:

1.  **¿Qué significa el fallo?**
    *   Según la documentación del Proyecto Integrado (`politicaConfiguracion.md`), un estado de `Failure` en GitHub Actions indica que la ejecución no tuvo éxito y, por lo tanto, el *commit* asociado a esa ejecución queda marcado como fallido.
    *   Este fallo generalmente significa que el software no se está comportando como se esperaba durante las pruebas automatizadas (como las **pruebas unitarias** o de **integración**). Se ha detectado un **`Fallo Funcional`**, es decir, un error en la funcionalidad del código.

2.  **¿Cuál es la implicación?**
    *   Un fallo en esta etapa indica la existencia de problemas de integración que **deben ser resueltos** antes de poder continuar integrando nuevo código. Ignorar este aviso podría introducir errores más graves en el sistema.

3.  **¿Qué pasos debo seguir?**
    *   **Revisa los logs de GitHub Actions:** Lo primero es entrar en los detalles de la ejecución fallida en GitHub. Allí podrás ver un registro detallado (*log*) que te indicará exactamente qué pruebas fallaron y, a menudo, por qué.
    *   **Identifica y corrige el error en tu código:** El fallo en las pruebas apunta a un defecto subyacente en tu implementación. Debes depurar tu código para encontrar la causa del comportamiento inesperado y corregirla.
    *   **Vuelve a ejecutar las pruebas en tu entorno local:** Antes de subir los cambios, asegúrate de que las pruebas ahora sí pasan en tu máquina.
    *   **Realiza un nuevo *commit* con la corrección:** Una vez solucionado el problema, sube los cambios. Esto activará de nuevo GitHub Actions, que volverá a ejecutar todo el proceso de pruebas sobre el código corregido.
    *   **Verifica que la nueva ejecución sea exitosa:** El objetivo es que el nuevo *commit* aparezca con un estado de éxito (*success*).

Recuerda que los fallos detectados durante las pruebas deben ser documentados formalmente en el **`Informe De Pruebas`**, que es una sección del **`Plan De Pruebas`** de tu proyecto.

En resumen, un fallo en GitHub Actions es una señal importante de que algo no va bien. Debes detenerte, analizar la causa, corregirla y verificar que la solución funciona antes de seguir adelante.",28.96,GRAPH,False,False,False
Hazme una lista de todos los elementos que se evalúan en el proyecto integrado,"Hola, analizando la información de las asignaturas, los elementos que se evalúan en el proyecto integrado son variados y cubren diferentes áreas del desarrollo de software.

Aquí tienes una lista de los principales componentes evaluables:

*   **Calidad y Auditoría:** La documentación indica que tanto la calidad del software como la auditoría son aspectos fundamentales que se evalúan. De hecho, el proyecto incluye tareas específicas que son valoradas en la asignatura de Calidad y Auditoría, como se menciona en el documento `evaluacionCalidad.md`.
*   **Métodos de Desarrollo:** Junto con la calidad y la auditoría, los métodos de desarrollo que aplicas en el proyecto son un pilar de la evaluación.
*   **Plan de Pruebas:** Se evalúa el diseño e implementación de un plan de pruebas para la aplicación. La información especifica que este documento contribuye directamente a la calificación final.
*   **Aplicación de Metodologías Ágiles (Scrum):** Dado que el proyecto se desarrolla siguiendo la metodología Scrum, se evalúan las prácticas ágiles del equipo. La existencia de rúbricas específicas, como se sugiere en el archivo `indexRubricasScrum.md`, indica que se valoran artefactos como las actas y las planificaciones de los sprints.
*   **Documentación del proyecto:** La creación de la documentación asociada, como diagramas y manuales, también forma parte de los elementos a evaluar.

En resumen, el proyecto se compone de diferentes **elementos evaluables** que se valoran en distintas etapas, y su calificación final integra la aplicación práctica de los conocimientos de asignaturas como Procesos de Ingeniería del Software, Calidad y Auditoría, y Métodos de Desarrollo.",28.64,GRAPH,False,False,False
¿Cuál es el elemento evaluable más importante en la asignatura Métodos de Desarrollo?,"Analizando la información disponible, la evaluación en la asignatura de Métodos de Desarrollo se centra de manera fundamental en el **proyecto integrado**.

Según la documentación, el proceso de evaluación para esta asignatura se define específicamente como el ""proceso para determinar el valor o calidad del proyecto integrado"". Esto indica que tu desempeño y aplicación de los conceptos se mide a través de este proyecto.

Dentro del proyecto, existen los ""Elementos Evaluables de Método de Desarrollo"", que son los aspectos concretos de la metodología que utilizáis y que se someten a evaluación para comprobar su eficacia y calidad. Por lo tanto, aunque se evalúan distintos aspectos, todos forman parte del desarrollo y la ejecución del proyecto integrado, convirtiéndolo en el elemento evaluable más importante.

Puedes encontrar más detalles sobre cómo se estructura esta valoración en los documentos de la carpeta `proyecto_Integrado/evaluacion/`, como `evaluacion.md`.",24.4,GRAPH,False,False,False
¿Qué herramientas voy a necesitar utilizar en el Proyecto Integrado? Dime donde se mencionan.,"Según la información proporcionada, el contexto indica que existe una lista de herramientas necesarias para el proyecto, pero no detalla cuáles son.

La mención se encuentra en la sección **# Herramientas**, donde se especifica:

> ""Esta página contiene una lista de las herramientas que se utilizarán para el desarrollo del proyecto integrado; así como las instrucciones necesarias para su instalación y configuración.""",15.97,VECTOR,False,False,False
